{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e0ccce8",
   "metadata": {
    "id": "8e0ccce8",
    "tags": []
   },
   "source": [
    "## Model Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68fe9ea2",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1650960921284,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "68fe9ea2"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "DATASET_SIZE = 30482\n",
    "MAX_EPOCHS = 20\n",
    "K_FOLDS = 5\n",
    "DATASET_PATH = 'covidx-cxr2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bfede4",
   "metadata": {
    "id": "69bfede4"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c6945d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6940,
     "status": "ok",
     "timestamp": 1650960928219,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "b2c6945d",
    "outputId": "5c72ab8a-1230-4f44-82c6-5edb3eeba2f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.8.0\n",
      "Tensorboard Version: 2.8.0\n",
      "WARNING:tensorflow:From <ipython-input-4-524b973928af>:28: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU Found: True\n"
     ]
    }
   ],
   "source": [
    "# import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "%reload_ext tensorboard\n",
    "import tensorboard\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import time\n",
    "\n",
    "# tensorflow-gpu check\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"Tensorboard Version:\", tensorboard.__version__)\n",
    "print(\"GPU Found:\", tf.test.is_gpu_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a26665",
   "metadata": {
    "executionInfo": {
     "elapsed": 3204,
     "status": "ok",
     "timestamp": 1650960931418,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "55a26665"
   },
   "outputs": [],
   "source": [
    "# set up hyper-parameters\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([128]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.1]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam']))\n",
    "HP_L_RATE= hp.HParam('learning_rate', hp.Discrete([0.001]))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "\n",
    "with tf.summary.create_file_writer('trained-classifiers/logs/hparam_tuning').as_default():\n",
    "    hp.hparams_config(\n",
    "        hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER, HP_L_RATE],\n",
    "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5197d1f5",
   "metadata": {
    "executionInfo": {
     "elapsed": 2175,
     "status": "ok",
     "timestamp": 1650960933586,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "5197d1f5"
   },
   "outputs": [],
   "source": [
    "# read in train data\n",
    "train_df = pd.read_csv(DATASET_PATH+'/train_COVIDx9B.txt', \n",
    "                       sep=\" \", header=None)\n",
    "# add columns to go from 0, 1, 2, 3 to patient id, filename, class etc\n",
    "train_df.columns=['patient id', 'filename', 'class', 'data source']\n",
    "\n",
    "# drop patient id and datasource as not needed\n",
    "train_df=train_df.drop(['patient id', 'data source'], axis=1 )\n",
    "\n",
    "# read in test data\n",
    "test_df = pd.read_csv(DATASET_PATH+'/test_COVIDx9B.txt', \n",
    "                      sep=\" \", header=None)\n",
    "# add columns to go from 0, 1, 2, 3 to patient id, filename, class etc\n",
    "test_df.columns=['patient id', 'filename', 'class', 'data source']\n",
    "\n",
    "# drop patient id and datasource as not needed\n",
    "test_df=test_df.drop(['patient id', 'data source'], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe14addd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650960933586,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "fe14addd",
    "outputId": "a032f68c-10ec-4511-9dd6-0156e4ca7dd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      "positive    16490\n",
      "negative    13992\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Test class counts:\n",
      "positive    200\n",
      "negative    200\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train class counts:\")\n",
    "print(train_df['class'].value_counts())\n",
    "print(\"\\nTest class counts:\")\n",
    "print(test_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e42bf5ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1650960933587,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "e42bf5ec",
    "outputId": "2d7356cc-fab3-45bc-dcb2-fc27ae0da5e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      "negative    15241\n",
      "positive    15241\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "negative  = train_df[train_df['class']=='negative']   # normal values in class column\n",
    "positive = train_df[train_df['class']=='positive']  # COVID-19 values in class column\n",
    "\n",
    "from sklearn.utils import resample\n",
    "# downsample training data to equal values of each class, to reduce class bias and reduce training time\n",
    "\n",
    "df_negative_downsampled = resample(negative, replace = True, n_samples = DATASET_SIZE//2)\n",
    "df_positive_downsampled = resample(positive, replace = True, n_samples = DATASET_SIZE//2) \n",
    "\n",
    "#concatenate\n",
    "train_df = pd.concat([df_negative_downsampled, df_positive_downsampled])\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "train_df = shuffle(train_df) # shuffling so that there is no particular sequence\n",
    "print(\"Train class counts:\")\n",
    "print(train_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7caf2941",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1650960933587,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "7caf2941",
    "outputId": "b35bc05b-1bea-4df4-fadc-4ca4c98f0555",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class counts:\n",
      "negative    15241\n",
      "positive    15241\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Test class counts:\n",
      "positive    200\n",
      "negative    200\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train class counts:\")\n",
    "print(train_df['class'].value_counts())\n",
    "print(\"\\nTest class counts:\")\n",
    "print(test_df['class'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a7105a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3953,
     "status": "ok",
     "timestamp": 1650960937536,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "4a7105a4",
    "outputId": "feab0487-4f18-4a0b-c946-e7852758b88d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# preprocess images\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input)\n",
    "\n",
    "test_gen = test_datagen.flow_from_dataframe(dataframe = test_df, directory=DATASET_PATH+'/test', x_col='filename',\n",
    "                                            y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, \n",
    "                                            color_mode='rgb', class_mode='binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc520d7a",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1650960937537,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "dc520d7a"
   },
   "outputs": [],
   "source": [
    "def preprocess_images_cv(train_index, val_index):\n",
    "    # find the section of the training data that the fold is located\n",
    "    training_data = train_df.iloc[train_index]\n",
    "    validation_data = train_df.iloc[val_index]\n",
    "    train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.applications.xception.preprocess_input,\n",
    "                                       rotation_range = 20, width_shift_range = 0.2, height_shift_range = 0.2, \n",
    "                                       shear_range = 0.2, zoom_range = 0.1, horizontal_flip = True, \n",
    "                                       vertical_flip = True)\n",
    "\n",
    "    # now get the images from directory with augmentation\n",
    "    \n",
    "    train_gen = train_datagen.flow_from_dataframe(dataframe = training_data, directory=DATASET_PATH+'/train', \n",
    "                                                  x_col='filename', y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                                  batch_size=BATCH_SIZE, color_mode='rgb', class_mode='binary')\n",
    "    valid_gen = test_datagen.flow_from_dataframe(dataframe = validation_data, directory=DATASET_PATH+'/train', \n",
    "                                                 x_col='filename', y_col='class', target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                                 batch_size=BATCH_SIZE,  color_mode='rgb', class_mode='binary')\n",
    "    return train_gen, valid_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174e3f4",
   "metadata": {
    "id": "4174e3f4"
   },
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96ce3019",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650960937537,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "96ce3019"
   },
   "outputs": [],
   "source": [
    "# required libraries for Xception\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "836aa1a9",
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1650960937537,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "836aa1a9"
   },
   "outputs": [],
   "source": [
    "def create_model(hparams):\n",
    "    inputs = keras.layers.Input(shape=(IMAGE_SIZE,IMAGE_SIZE,3))\n",
    "    \n",
    "    # create the base pre-trained model\n",
    "    base_model = keras.applications.Xception(weights='imagenet', input_shape = (IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                                  include_top=False)\n",
    "    # train all but the last 3 layers of the model\n",
    "    for layer in base_model.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    model1 = keras.Sequential()\n",
    "    model1.add(inputs)\n",
    "    model1.add(base_model)\n",
    "    \n",
    "    # create the base pre-trained model\n",
    "    base_model2 = keras.applications.ResNet50V2(weights='imagenet', input_shape = (IMAGE_SIZE,IMAGE_SIZE,3),\n",
    "                                                  include_top=False)\n",
    "    # train all but the last 3 layers of the model   \n",
    "    for layer in base_model2.layers[:-3]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    model2 = keras.Sequential()\n",
    "    model2.add(inputs)\n",
    "    model2.add(base_model2)\n",
    "    \n",
    "    # merge the two models together and add output layers\n",
    "    merged = keras.layers.Concatenate()([model1.output,model2.output])\n",
    "    z = keras.layers.Conv2D(1024,1, padding='same')(merged)\n",
    "    z = keras.layers.Flatten()(z)\n",
    "    z = keras.layers.Dropout(hparams[HP_DROPOUT])(z)\n",
    "    z = keras.layers.Dense(hparams[HP_NUM_UNITS], activation='relu',\n",
    "                                  kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                                  bias_regularizer=regularizers.l2(1e-4),\n",
    "                                  activity_regularizer=regularizers.l2(1e-5)\n",
    "                                  )(z)\n",
    "    z = keras.layers.Dense(1, activation=\"sigmoid\")(z)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=z)\n",
    "    \n",
    "    # compile model\n",
    "    optimizer_name = hparams[HP_OPTIMIZER]\n",
    "    learning_rate = hparams[HP_L_RATE]\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        raise ValueError(\"unexpected optimizer name: %r\" % (optimizer_name,))\n",
    "\n",
    "    model.compile(optimizer = optimizer,\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8275562",
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1650960946840,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "b8275562"
   },
   "outputs": [],
   "source": [
    "def get_model_name(k):\n",
    "    return str(\"Xception-ResNet-Binary-\" + \"Fold-\"+str(k)+\"-\"+datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8faa2fa4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 74697454,
     "status": "ok",
     "timestamp": 1651035644285,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "8faa2fa4",
    "outputId": "7f29127d-a1b2-4b20-8369-ab5879544d0f",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HPARAMS: {'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "--- Starting trial: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 1 invalid image filename(s) in x_col=\"filename\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24384 validated image filenames belonging to 2 classes.\n",
      "Found 6097 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "762/762 [==============================] - 13345s 17s/step - loss: 0.6338 - accuracy: 0.8672 - val_loss: 0.4169 - val_accuracy: 0.9190 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.4800 - accuracy: 0.8889\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "762/762 [==============================] - 710s 932ms/step - loss: 0.4800 - accuracy: 0.8889 - val_loss: 0.5522 - val_accuracy: 0.9365 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.4571 - accuracy: 0.9259\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "762/762 [==============================] - 706s 926ms/step - loss: 0.4571 - accuracy: 0.9259 - val_loss: 0.4431 - val_accuracy: 0.8952 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "762/762 [==============================] - 718s 942ms/step - loss: 0.3467 - accuracy: 0.9403 - val_loss: 0.3341 - val_accuracy: 0.9451 - lr: 2.5000e-04\n",
      "Epoch 5/20\n",
      "762/762 [==============================] - 720s 945ms/step - loss: 0.3188 - accuracy: 0.9423 - val_loss: 0.3314 - val_accuracy: 0.9410 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "762/762 [==============================] - 729s 956ms/step - loss: 0.3033 - accuracy: 0.9433 - val_loss: 0.3089 - val_accuracy: 0.9437 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9443\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "762/762 [==============================] - 714s 937ms/step - loss: 0.2834 - accuracy: 0.9443 - val_loss: 0.3206 - val_accuracy: 0.9451 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "762/762 [==============================] - 721s 947ms/step - loss: 0.2543 - accuracy: 0.9510 - val_loss: 0.2267 - val_accuracy: 0.9570 - lr: 1.2500e-04\n",
      "Epoch 9/20\n",
      "762/762 [==============================] - 723s 949ms/step - loss: 0.2295 - accuracy: 0.9501 - val_loss: 0.2264 - val_accuracy: 0.9534 - lr: 1.2500e-04\n",
      "Epoch 10/20\n",
      "762/762 [==============================] - 724s 950ms/step - loss: 0.2166 - accuracy: 0.9540 - val_loss: 0.2226 - val_accuracy: 0.9556 - lr: 1.2500e-04\n",
      "Epoch 11/20\n",
      "762/762 [==============================] - 724s 951ms/step - loss: 0.2054 - accuracy: 0.9544 - val_loss: 0.2093 - val_accuracy: 0.9544 - lr: 1.2500e-04\n",
      "Epoch 12/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.1995 - accuracy: 0.9554\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "762/762 [==============================] - 716s 939ms/step - loss: 0.1995 - accuracy: 0.9554 - val_loss: 0.2323 - val_accuracy: 0.9516 - lr: 1.2500e-04\n",
      "Epoch 13/20\n",
      "762/762 [==============================] - 723s 949ms/step - loss: 0.1937 - accuracy: 0.9608 - val_loss: 0.2033 - val_accuracy: 0.9546 - lr: 6.2500e-05\n",
      "Epoch 14/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9614\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "762/762 [==============================] - 718s 942ms/step - loss: 0.1852 - accuracy: 0.9614 - val_loss: 0.2167 - val_accuracy: 0.9515 - lr: 6.2500e-05\n",
      "Epoch 15/20\n",
      "762/762 [==============================] - 722s 948ms/step - loss: 0.1768 - accuracy: 0.9626 - val_loss: 0.2020 - val_accuracy: 0.9567 - lr: 3.1250e-05\n",
      "Epoch 16/20\n",
      "762/762 [==============================] - 740s 972ms/step - loss: 0.1716 - accuracy: 0.9618 - val_loss: 0.1964 - val_accuracy: 0.9569 - lr: 3.1250e-05\n",
      "Epoch 17/20\n",
      "762/762 [==============================] - 727s 954ms/step - loss: 0.1675 - accuracy: 0.9627 - val_loss: 0.1835 - val_accuracy: 0.9569 - lr: 3.1250e-05\n",
      "Epoch 18/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.1629 - accuracy: 0.9643\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "762/762 [==============================] - 716s 940ms/step - loss: 0.1629 - accuracy: 0.9643 - val_loss: 0.1962 - val_accuracy: 0.9552 - lr: 3.1250e-05\n",
      "Epoch 19/20\n",
      "762/762 [==============================] - ETA: 0s - loss: 0.1591 - accuracy: 0.9648\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "762/762 [==============================] - 714s 937ms/step - loss: 0.1591 - accuracy: 0.9648 - val_loss: 0.1972 - val_accuracy: 0.9544 - lr: 1.5625e-05\n",
      "Epoch 20/20\n",
      "762/762 [==============================] - 725s 952ms/step - loss: 0.1563 - accuracy: 0.9654 - val_loss: 0.1832 - val_accuracy: 0.9583 - lr: 7.8125e-06\n",
      "--- Starting trial: 1\n",
      "Found 24385 validated image filenames belonging to 2 classes.\n",
      "Found 6097 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "763/763 [==============================] - 726s 944ms/step - loss: 0.7369 - accuracy: 0.8231 - val_loss: 0.4957 - val_accuracy: 0.8922 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.5830 - accuracy: 0.8757\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "763/763 [==============================] - 720s 944ms/step - loss: 0.5830 - accuracy: 0.8757 - val_loss: 0.5116 - val_accuracy: 0.8724 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "763/763 [==============================] - 734s 962ms/step - loss: 0.4706 - accuracy: 0.9126 - val_loss: 0.4680 - val_accuracy: 0.9367 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.4427 - accuracy: 0.9181\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "763/763 [==============================] - 720s 943ms/step - loss: 0.4427 - accuracy: 0.9181 - val_loss: 0.5336 - val_accuracy: 0.9283 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "763/763 [==============================] - 724s 949ms/step - loss: 0.3508 - accuracy: 0.9314 - val_loss: 0.3029 - val_accuracy: 0.9492 - lr: 2.5000e-04\n",
      "Epoch 6/20\n",
      "763/763 [==============================] - 734s 962ms/step - loss: 0.2796 - accuracy: 0.9396 - val_loss: 0.2500 - val_accuracy: 0.9515 - lr: 2.5000e-04\n",
      "Epoch 7/20\n",
      "763/763 [==============================] - 735s 963ms/step - loss: 0.2631 - accuracy: 0.9370 - val_loss: 0.2320 - val_accuracy: 0.9511 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2480 - accuracy: 0.9415\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "763/763 [==============================] - 719s 942ms/step - loss: 0.2480 - accuracy: 0.9415 - val_loss: 0.2436 - val_accuracy: 0.9528 - lr: 2.5000e-04\n",
      "Epoch 9/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2282 - accuracy: 0.9467\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "763/763 [==============================] - 715s 937ms/step - loss: 0.2282 - accuracy: 0.9467 - val_loss: 0.2369 - val_accuracy: 0.9524 - lr: 1.2500e-04\n",
      "Epoch 10/20\n",
      "763/763 [==============================] - 728s 955ms/step - loss: 0.2082 - accuracy: 0.9535 - val_loss: 0.1974 - val_accuracy: 0.9600 - lr: 6.2500e-05\n",
      "Epoch 11/20\n",
      "763/763 [==============================] - 735s 963ms/step - loss: 0.1914 - accuracy: 0.9554 - val_loss: 0.1960 - val_accuracy: 0.9565 - lr: 6.2500e-05\n",
      "Epoch 12/20\n",
      "763/763 [==============================] - 734s 962ms/step - loss: 0.1857 - accuracy: 0.9544 - val_loss: 0.1852 - val_accuracy: 0.9593 - lr: 6.2500e-05\n",
      "Epoch 13/20\n",
      "763/763 [==============================] - 738s 967ms/step - loss: 0.1809 - accuracy: 0.9576 - val_loss: 0.1741 - val_accuracy: 0.9626 - lr: 6.2500e-05\n",
      "Epoch 14/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9594\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "763/763 [==============================] - 720s 944ms/step - loss: 0.1748 - accuracy: 0.9594 - val_loss: 0.1788 - val_accuracy: 0.9619 - lr: 6.2500e-05\n",
      "Epoch 15/20\n",
      "763/763 [==============================] - 727s 953ms/step - loss: 0.1762 - accuracy: 0.9582 - val_loss: 0.1702 - val_accuracy: 0.9636 - lr: 3.1250e-05\n",
      "Epoch 16/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9605\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "763/763 [==============================] - 720s 943ms/step - loss: 0.1693 - accuracy: 0.9605 - val_loss: 0.1717 - val_accuracy: 0.9654 - lr: 3.1250e-05\n",
      "Epoch 17/20\n",
      "763/763 [==============================] - 728s 955ms/step - loss: 0.1597 - accuracy: 0.9632 - val_loss: 0.1660 - val_accuracy: 0.9642 - lr: 1.5625e-05\n",
      "Epoch 18/20\n",
      "763/763 [==============================] - 727s 953ms/step - loss: 0.1609 - accuracy: 0.9621 - val_loss: 0.1593 - val_accuracy: 0.9647 - lr: 1.5625e-05\n",
      "Epoch 19/20\n",
      "763/763 [==============================] - 729s 955ms/step - loss: 0.1544 - accuracy: 0.9630 - val_loss: 0.1569 - val_accuracy: 0.9665 - lr: 1.5625e-05\n",
      "Epoch 20/20\n",
      "763/763 [==============================] - 730s 957ms/step - loss: 0.1544 - accuracy: 0.9647 - val_loss: 0.1522 - val_accuracy: 0.9679 - lr: 1.5625e-05\n",
      "--- Starting trial: 2\n",
      "Found 24386 validated image filenames belonging to 2 classes.\n",
      "Found 6096 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "763/763 [==============================] - 732s 953ms/step - loss: 0.6455 - accuracy: 0.8777 - val_loss: 0.5058 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.8664\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "763/763 [==============================] - 723s 947ms/step - loss: 0.6791 - accuracy: 0.8664 - val_loss: 0.8987 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "763/763 [==============================] - 730s 957ms/step - loss: 0.5334 - accuracy: 0.9164 - val_loss: 0.4749 - val_accuracy: 0.9250 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "763/763 [==============================] - 728s 954ms/step - loss: 0.4763 - accuracy: 0.9205 - val_loss: 0.4301 - val_accuracy: 0.9401 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "763/763 [==============================] - 735s 964ms/step - loss: 0.3960 - accuracy: 0.9269 - val_loss: 0.3651 - val_accuracy: 0.9459 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.3852 - accuracy: 0.9309\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "763/763 [==============================] - 722s 946ms/step - loss: 0.3852 - accuracy: 0.9309 - val_loss: 0.3791 - val_accuracy: 0.9209 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "763/763 [==============================] - 728s 954ms/step - loss: 0.3177 - accuracy: 0.9416 - val_loss: 0.2994 - val_accuracy: 0.9547 - lr: 2.5000e-04\n",
      "Epoch 8/20\n",
      "763/763 [==============================] - 745s 976ms/step - loss: 0.2783 - accuracy: 0.9454 - val_loss: 0.2596 - val_accuracy: 0.9537 - lr: 2.5000e-04\n",
      "Epoch 9/20\n",
      "763/763 [==============================] - 747s 979ms/step - loss: 0.2709 - accuracy: 0.9456 - val_loss: 0.2574 - val_accuracy: 0.9534 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "763/763 [==============================] - 744s 975ms/step - loss: 0.2545 - accuracy: 0.9486 - val_loss: 0.2561 - val_accuracy: 0.9514 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9480\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "763/763 [==============================] - 714s 936ms/step - loss: 0.2599 - accuracy: 0.9480 - val_loss: 0.2865 - val_accuracy: 0.9385 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "763/763 [==============================] - 716s 939ms/step - loss: 0.2273 - accuracy: 0.9551 - val_loss: 0.2267 - val_accuracy: 0.9549 - lr: 1.2500e-04\n",
      "Epoch 13/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2185 - accuracy: 0.9569\n",
      "Epoch 13: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "763/763 [==============================] - 709s 930ms/step - loss: 0.2185 - accuracy: 0.9569 - val_loss: 0.2300 - val_accuracy: 0.9582 - lr: 1.2500e-04\n",
      "Epoch 14/20\n",
      "763/763 [==============================] - 724s 949ms/step - loss: 0.2071 - accuracy: 0.9583 - val_loss: 0.2020 - val_accuracy: 0.9605 - lr: 6.2500e-05\n",
      "Epoch 15/20\n",
      "763/763 [==============================] - 753s 987ms/step - loss: 0.1902 - accuracy: 0.9606 - val_loss: 0.1954 - val_accuracy: 0.9608 - lr: 6.2500e-05\n",
      "Epoch 16/20\n",
      "763/763 [==============================] - 724s 950ms/step - loss: 0.1846 - accuracy: 0.9604 - val_loss: 0.1884 - val_accuracy: 0.9618 - lr: 6.2500e-05\n",
      "Epoch 17/20\n",
      "763/763 [==============================] - 726s 952ms/step - loss: 0.1737 - accuracy: 0.9630 - val_loss: 0.1843 - val_accuracy: 0.9598 - lr: 6.2500e-05\n",
      "Epoch 18/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9617\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "763/763 [==============================] - 710s 930ms/step - loss: 0.1755 - accuracy: 0.9617 - val_loss: 0.1890 - val_accuracy: 0.9601 - lr: 6.2500e-05\n",
      "Epoch 19/20\n",
      "763/763 [==============================] - 724s 949ms/step - loss: 0.1712 - accuracy: 0.9623 - val_loss: 0.1811 - val_accuracy: 0.9662 - lr: 3.1250e-05\n",
      "Epoch 20/20\n",
      "763/763 [==============================] - 721s 944ms/step - loss: 0.1643 - accuracy: 0.9640 - val_loss: 0.1788 - val_accuracy: 0.9647 - lr: 3.1250e-05\n",
      "--- Starting trial: 3\n",
      "Found 24386 validated image filenames belonging to 2 classes.\n",
      "Found 6096 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "763/763 [==============================] - 729s 948ms/step - loss: 0.7519 - accuracy: 0.8069 - val_loss: 0.5102 - val_accuracy: 0.9199 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.5750 - accuracy: 0.8760\n",
      "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "763/763 [==============================] - 722s 947ms/step - loss: 0.5750 - accuracy: 0.8760 - val_loss: 0.5597 - val_accuracy: 0.9172 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "763/763 [==============================] - 730s 956ms/step - loss: 0.4855 - accuracy: 0.9132 - val_loss: 0.4885 - val_accuracy: 0.9311 - lr: 5.0000e-04\n",
      "Epoch 4/20\n",
      "763/763 [==============================] - 730s 956ms/step - loss: 0.4629 - accuracy: 0.9191 - val_loss: 0.4003 - val_accuracy: 0.9332 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "763/763 [==============================] - 730s 957ms/step - loss: 0.4032 - accuracy: 0.9262 - val_loss: 0.3674 - val_accuracy: 0.9421 - lr: 5.0000e-04\n",
      "Epoch 6/20\n",
      "763/763 [==============================] - 731s 959ms/step - loss: 0.3775 - accuracy: 0.9204 - val_loss: 0.3518 - val_accuracy: 0.9344 - lr: 5.0000e-04\n",
      "Epoch 7/20\n",
      "763/763 [==============================] - 732s 959ms/step - loss: 0.3568 - accuracy: 0.9281 - val_loss: 0.3491 - val_accuracy: 0.9408 - lr: 5.0000e-04\n",
      "Epoch 8/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.3864 - accuracy: 0.9281\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "763/763 [==============================] - 724s 948ms/step - loss: 0.3864 - accuracy: 0.9281 - val_loss: 0.3806 - val_accuracy: 0.9388 - lr: 5.0000e-04\n",
      "Epoch 9/20\n",
      "763/763 [==============================] - 731s 958ms/step - loss: 0.3378 - accuracy: 0.9427 - val_loss: 0.2981 - val_accuracy: 0.9485 - lr: 2.5000e-04\n",
      "Epoch 10/20\n",
      "763/763 [==============================] - 744s 975ms/step - loss: 0.2952 - accuracy: 0.9461 - val_loss: 0.2931 - val_accuracy: 0.9441 - lr: 2.5000e-04\n",
      "Epoch 11/20\n",
      "763/763 [==============================] - 732s 960ms/step - loss: 0.2799 - accuracy: 0.9453 - val_loss: 0.2823 - val_accuracy: 0.9532 - lr: 2.5000e-04\n",
      "Epoch 12/20\n",
      "763/763 [==============================] - 735s 963ms/step - loss: 0.2663 - accuracy: 0.9487 - val_loss: 0.2689 - val_accuracy: 0.9459 - lr: 2.5000e-04\n",
      "Epoch 13/20\n",
      "763/763 [==============================] - 733s 960ms/step - loss: 0.2783 - accuracy: 0.9488 - val_loss: 0.2496 - val_accuracy: 0.9536 - lr: 2.5000e-04\n",
      "Epoch 14/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2641 - accuracy: 0.9506\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "763/763 [==============================] - 724s 949ms/step - loss: 0.2641 - accuracy: 0.9506 - val_loss: 0.2591 - val_accuracy: 0.9570 - lr: 2.5000e-04\n",
      "Epoch 15/20\n",
      "763/763 [==============================] - 731s 958ms/step - loss: 0.2302 - accuracy: 0.9545 - val_loss: 0.2223 - val_accuracy: 0.9624 - lr: 1.2500e-04\n",
      "Epoch 16/20\n",
      "763/763 [==============================] - 738s 967ms/step - loss: 0.2111 - accuracy: 0.9582 - val_loss: 0.2029 - val_accuracy: 0.9619 - lr: 1.2500e-04\n",
      "Epoch 17/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 0.2015 - accuracy: 0.9564\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "763/763 [==============================] - 728s 954ms/step - loss: 0.2015 - accuracy: 0.9564 - val_loss: 0.2119 - val_accuracy: 0.9593 - lr: 1.2500e-04\n",
      "Epoch 18/20\n",
      "763/763 [==============================] - 733s 961ms/step - loss: 0.1848 - accuracy: 0.9629 - val_loss: 0.1961 - val_accuracy: 0.9624 - lr: 6.2500e-05\n",
      "Epoch 19/20\n",
      "763/763 [==============================] - 737s 966ms/step - loss: 0.1761 - accuracy: 0.9629 - val_loss: 0.1855 - val_accuracy: 0.9657 - lr: 6.2500e-05\n",
      "Epoch 20/20\n",
      "763/763 [==============================] - 734s 962ms/step - loss: 0.1748 - accuracy: 0.9623 - val_loss: 0.1790 - val_accuracy: 0.9669 - lr: 6.2500e-05\n",
      "--- Starting trial: 4\n",
      "Found 24386 validated image filenames belonging to 2 classes.\n",
      "Found 6096 validated image filenames belonging to 2 classes.\n",
      "WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n",
      "Epoch 1/20\n",
      "763/763 [==============================] - 735s 957ms/step - loss: 0.7978 - accuracy: 0.7700 - val_loss: 0.8817 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "763/763 [==============================] - 739s 969ms/step - loss: 0.9159 - accuracy: 0.5009 - val_loss: 0.8685 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 1.0540 - accuracy: 0.5027\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "763/763 [==============================] - 726s 951ms/step - loss: 1.0540 - accuracy: 0.5027 - val_loss: 1.4152 - val_accuracy: 0.5000 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 0.5004\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "763/763 [==============================] - 725s 950ms/step - loss: 1.4459 - accuracy: 0.5004 - val_loss: 1.2091 - val_accuracy: 0.5002 - lr: 5.0000e-04\n",
      "Epoch 5/20\n",
      "763/763 [==============================] - ETA: 0s - loss: 1.0966 - accuracy: 0.6549Restoring model weights from the end of the best epoch: 2.\n",
      "\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "763/763 [==============================] - 727s 954ms/step - loss: 1.0966 - accuracy: 0.6549 - val_loss: 0.9230 - val_accuracy: 0.8748 - lr: 2.5000e-04\n",
      "Epoch 5: early stopping\n"
     ]
    }
   ],
   "source": [
    "# perform HP tuning and CV on the model on the data\n",
    "Y = train_df['class']\n",
    "trained_models = []\n",
    "\n",
    "# iterate through hyper-parameters\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in HP_DROPOUT.domain.values:\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            for learning_rate in HP_L_RATE.domain.values:\n",
    "                # instantiate k folds and hyper-parameters for this iteration\n",
    "                skf = StratifiedKFold(n_splits = K_FOLDS, shuffle = True) \n",
    "                k_i = 0\n",
    "                k_fold_models = []\n",
    "                elapsed_times = []\n",
    "                hparams = {\n",
    "                    HP_NUM_UNITS: num_units,\n",
    "                    HP_DROPOUT: dropout_rate,\n",
    "                    HP_OPTIMIZER: optimizer,\n",
    "                    HP_L_RATE: learning_rate\n",
    "                }\n",
    "                print('HPARAMS:',{h.name: hparams[h] for h in hparams})\n",
    "                \n",
    "                # iterate through k folds\n",
    "                for train_index, val_index in skf.split(np.zeros(len(Y)),Y):\n",
    "                    print('--- Starting trial: %s' % k_i)\n",
    "                    t = time.process_time() # begin timing model\n",
    "                    train_gen, valid_gen = preprocess_images_cv(train_index, val_index) # fetch dataset for this fold\n",
    "                    \n",
    "                    # set up logging directories and callbacks\n",
    "                    logdir = os.path.join('trained-classifiers','logs','fit', get_model_name(k_i))\n",
    "                    hpdir = os.path.join('trained-classifiers','logs','hparam_tuning', get_model_name(k_i))\n",
    "                    modeldir = os.path.join('model-checkpoints',str(get_model_name(k_i)+\".h5\"))\n",
    "                    callbacks = [\n",
    "                        keras.callbacks.ModelCheckpoint(filepath=modeldir, save_best_only=True, verbose = 0),\n",
    "                        keras.callbacks.EarlyStopping(patience=3, monitor='val_loss', verbose=1, restore_best_weights=True),\n",
    "                        keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, verbose=1),\n",
    "                        keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "                      ]\n",
    "                    \n",
    "                    # create the model\n",
    "                    hp.hparams(hparams)  \n",
    "                    model = create_model(hparams)\n",
    "                    \n",
    "                    # train model\n",
    "                    model.fit(train_gen, validation_data=valid_gen, epochs=MAX_EPOCHS, callbacks=callbacks)\n",
    "                    \n",
    "                    # record the values used in this trial\n",
    "                    elapsed_times.append(time.process_time() - t)\n",
    "                    k_fold_models.append(modeldir)\n",
    "                    \n",
    "                    # clean memory\n",
    "                    del model, train_gen, valid_gen\n",
    "                    keras.backend.clear_session()\n",
    "                    k_i += 1\n",
    "                    \n",
    "                trained_models.append([hparams, k_fold_models, elapsed_times])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4d6530",
   "metadata": {
    "id": "7d4d6530"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9851f1f7",
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1651035644285,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "9851f1f7"
   },
   "outputs": [],
   "source": [
    "# import libraries for evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69b88b94",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 609460,
     "status": "ok",
     "timestamp": 1651036253742,
     "user": {
      "displayName": "Laurence Brown",
      "userId": "02353821870267800674"
     },
     "user_tz": -60
    },
    "id": "69b88b94",
    "outputId": "32bab56a-fb29-4afc-9a2c-58b6ed25ece8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 21s 1s/step - loss: 0.2571 - accuracy: 0.9325\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.2899 - accuracy: 0.9050\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.3194 - accuracy: 0.9125\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.3384 - accuracy: 0.8700\n",
      "13/13 [==============================] - 19s 1s/step - loss: 0.8685 - accuracy: 0.5000\n",
      "SCORE FOR HPARAMS: {'num_units': 128, 'dropout': 0.1, 'optimizer': 'adam', 'learning_rate': 0.001}\n",
      "Mean accuracy: 0.824\n",
      "Mean k_accuracy; 0.8240000009536743\n",
      "Mean precision: 0.7787424291605196\n",
      "Mean recall: 0.666\n",
      "Mean f1: 0.7176785599403724\n",
      "Mean training time: 10948.4695840846\n"
     ]
    }
   ],
   "source": [
    "# iterate through hyper-parameter configurations\n",
    "for j in trained_models:\n",
    "    model = create_model(j[0])\n",
    "    accuracies = []\n",
    "    k_accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "    \n",
    "    # iterate through each folds model\n",
    "    for i in j[1]:\n",
    "        model.load_weights(i)\n",
    "        test_pred = model.predict(test_gen)\n",
    "        y_pred = np.rint(test_pred).flatten()\n",
    "        y_test= [test_gen.class_indices[k] for k in test_df['class'].values.tolist()]\n",
    "        k_accuracies.append(model.evaluate(test_gen)[1])\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, zero_division=0))\n",
    "        recalls.append(recall_score(y_test, y_pred))\n",
    "        f1s.append(f1_score(y_test, y_pred))\n",
    "        tn_x, fp_x, fn_x, tp_x = confusion_matrix(y_test, y_pred).ravel()\n",
    "        tp.append(tp_x)\n",
    "        fp.append(fp_x)\n",
    "        tn.append(tn_x)\n",
    "        fn.append(fn_x)\n",
    "\n",
    "    print(\"SCORE FOR HPARAMS:\", {h.name: j[0][h] for h in j[0]})\n",
    "    print(\"Mean accuracy:\", mean(accuracies))\n",
    "    print(\"Mean k_accuracy;\", mean(k_accuracies))\n",
    "    print(\"Mean precision:\", mean(precisions))\n",
    "    print(\"Mean recall:\", mean(recalls))\n",
    "    print(\"Mean f1:\", mean(f1s))\n",
    "    print(\"Mean training time:\", mean(j[2]))\n",
    "    \n",
    "    # retreive hyper-parameters\n",
    "    hdict = {h.name: j[0][h] for h in j[0]}\n",
    "    \n",
    "    # save results to file\n",
    "    df =  pd.DataFrame(np.array([[str(j[1]),\n",
    "                                  hdict.get('num_units'), hdict.get('dropout'), hdict.get('optimizer'), \n",
    "                                  hdict.get('learning_rate'),IMAGE_SIZE, BATCH_SIZE, DATASET_SIZE, MAX_EPOCHS, K_FOLDS,\n",
    "                                  mean(accuracies), mean(k_accuracies), mean(precisions), mean(recalls), mean(f1s),\n",
    "                                  mean(tn), mean(fp), mean(fn), mean(tp), mean(j[2])\n",
    "                                 ]]),\n",
    "                       columns=['Model Names','num_units', 'dropout','optimizer','learning_rate',\n",
    "                                'IMAGE_SIZE', 'BATCH_SIZE', 'DATASET_SIZE', 'MAX_EPOCHS',\n",
    "                                'K_FOLDS','Accuracy', 'K_accuracy', 'Precision', 'Recall', 'f1 Score', \n",
    "                                'True Negatives', ' False Positives', 'False Negatives', 'True Positives', 'Training Time'])\n",
    "    with open('trained-classifiers/Xception-ResNet.csv', 'a') as f:\n",
    "        df.to_csv(f, mode='a', header=f.tell()==0, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f74fbe",
   "metadata": {
    "id": "96f74fbe"
   },
   "source": [
    "NOTE: Accuracy and loss graphs can be seen on TensorBoard, run \"%tensorboard --logdir logs --host 0.0.0.0\" to open"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "FINAL Xception-Binary-Hparams-Improved-v4.ipynb",
   "provenance": [
    {
     "file_id": "1keBbgHU9796Qh-QUit5pQf6qJkdmWIIH",
     "timestamp": 1650905483125
    },
    {
     "file_id": "1BmReUMOHcmuct96QlZfg3LYmHHktVnno",
     "timestamp": 1650894059685
    },
    {
     "file_id": "1yNjHdq-BuZDeCcrVuiCfEBDPnd3L3g_t",
     "timestamp": 1650892599357
    },
    {
     "file_id": "10KjaZLI44g1FgHI6woKI1m50AaP3emKx",
     "timestamp": 1650547803270
    },
    {
     "file_id": "https://github.com/laurencebrwn/ml-covid19-eval/blob/main/Xception-Binary-Hparams-Improved-v3.ipynb",
     "timestamp": 1649112605425
    }
   ]
  },
  "environment": {
   "kernel": "python3",
   "name": "managed-notebooks.m90",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/managed-notebooks:m90"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
